{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a72bf6-07eb-48b7-9516-6e1c6ae372ce",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression: Breast Cancer Detection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e1830f-2691-4e2e-800b-bf8c765ad940",
   "metadata": {},
   "source": [
    "Dataset (online URL): We’ll use the UCI “Breast Cancer Wisconsin (Diagnostic)” dataset. You can download it as a ZIP directly and read wdbc.data inside. It has 569 rows and 30 real-valued features (plus ID and label M/B). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5525525-e38e-40e2-b324-86cb982fda02",
   "metadata": {},
   "source": [
    "# Math Behind Logistic Regression\n",
    "\n",
    "- Logistic regression models the probability of a binary outcome \\( y \\in \\{0,1\\} \\) given input features \\( X \\), by estimating a linear combination of the inputs followed by a sigmoid transformation.\n",
    "\n",
    "- The linear combination (logits) is:\n",
    "\n",
    "  $$\n",
    "  z = w_0 + w_1 x_1 + \\cdots + w_n x_n = \\mathbf{w}^\\top \\tilde{\\mathbf{x}}\n",
    "  $$\n",
    "\n",
    "  where \\( \\mathbf{w} \\) are the weights (including bias \\( w_0 \\)) and \\( \\tilde{\\mathbf{x}} \\) is the feature vector with an added bias term.\n",
    "\n",
    "- The sigmoid (logistic) function transforms this linear combination into a probability between 0 and 1:\n",
    "\n",
    "  $$\n",
    "  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "  $$\n",
    "\n",
    "- Thus, the predicted probability that the outcome is 1 is:\n",
    "\n",
    "  $$\n",
    "  p(y=1|X) = \\sigma(z) = \\frac{1}{1 + e^{-(w_0 + \\mathbf{w}^\\top \\mathbf{x})}}\n",
    "  $$\n",
    "\n",
    "- The odds of the outcome are given by:\n",
    "\n",
    "  $$\n",
    "  \\frac{p}{1-p} = e^z\n",
    "  $$\n",
    "\n",
    "  where \\( p = p(y=1 | X) \\).\n",
    "\n",
    "- Taking the natural logarithm of the odds gives the log-odds or logit:\n",
    "\n",
    "  $$\n",
    "  \\log \\frac{p}{1-p} = z = w_0 + \\mathbf{w}^\\top \\mathbf{x}\n",
    "  $$\n",
    "\n",
    "- The parameters \\( w_0, \\mathbf{w} \\) are estimated by maximizing the likelihood of the observed data, which equivalently minimizes the logistic loss or cross-entropy loss function:\n",
    "\n",
    "  $$\n",
    "  J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\Big[ y^{(i)} \\log h_\\theta(x^{(i)}) + (1 - y^{(i)}) \\log (1 - h_\\theta(x^{(i)})) \\Big]\n",
    "  $$\n",
    "\n",
    "  where \\( h_\\theta(x) = \\sigma(z) \\) is the predicted probability for input \\( x^{(i)} \\), and \\( m \\) is the number of training samples.\n",
    "\n",
    "- This loss function encourages the predicted probabilities to be close to the true labels.\n",
    "\n",
    "Overall, logistic regression is a generalized linear model that uses the logistic function to model the probability of a binary outcome\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a06bc5dd-882e-4759-978e-679a6f0886f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  target  \n",
       "0                  0.11890       1  \n",
       "1                  0.08902       1  \n",
       "2                  0.08758       1  \n",
       "3                  0.17300       1  \n",
       "4                  0.07678       1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io, zipfile, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Direct ZIP from UCI (contains wdbc.data and wdbc.names)\n",
    "UCI_ZIP_URL = \"https://archive.ics.uci.edu/static/public/17/breast%2Bcancer%2Bwisconsin%2Bdiagnostic.zip\"\n",
    "\n",
    "resp = requests.get(UCI_ZIP_URL)\n",
    "resp.raise_for_status()\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:\n",
    "    with zf.open('wdbc.data') as f:\n",
    "        # Build the column names programmatically (matches scikit-learn’s)\n",
    "        base = ['radius','texture','perimeter','area','smoothness',\n",
    "                'compactness','concavity','concave_points','symmetry','fractal_dimension']\n",
    "        feature_names = [f\"{b}_{stat}\" for stat in ['mean','se','worst'] for b in base]\n",
    "        cols = ['ID','Diagnosis'] + feature_names\n",
    "        df = pd.read_csv(f, header=None, names=cols)\n",
    "\n",
    "# Encode labels: M -> 1 (malignant), B -> 0 (benign)\n",
    "df['target'] = (df['Diagnosis'] == 'M').astype(int)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc16a864-a07d-46d0-b3e7-2c3e369bbdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df[feature_names].values\n",
    "y = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize *using training set only*\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std  = scaler.transform(X_test)\n",
    "X_train_std.shape, X_test_std.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eb4100c-6fb3-4017-8c4a-6a1a38e13842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1800, np.float64(0.054833708366869724)),\n",
       " (1850, np.float64(0.05457702677666139)),\n",
       " (1900, np.float64(0.05432892634093721)),\n",
       " (1950, np.float64(0.054088894896411846)),\n",
       " (1999, np.float64(0.05386103978413063))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper: numerically-stable sigmoid\n",
    "def sigmoid(z):\n",
    "    # clip z to avoid overflow in exp\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def log_loss(y_true, y_hat, eps=1e-12):\n",
    "    y_hat = np.clip(y_hat, eps, 1-eps)\n",
    "    return -np.mean(y_true*np.log(y_hat) + (1-y_true)*np.log(1-y_hat))\n",
    "\n",
    "# Add intercept column\n",
    "def add_intercept(X):\n",
    "    return np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "Xtr = add_intercept(X_train_std)\n",
    "Xte = add_intercept(X_test_std)\n",
    "\n",
    "# Initialize weights (theta = [b, w1, ..., wn])\n",
    "rng = np.random.default_rng(0)\n",
    "theta = rng.normal(scale=0.01, size=Xtr.shape[1])\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1      # learning rate\n",
    "epochs = 2000\n",
    "\n",
    "loss_history = []\n",
    "for t in range(epochs):\n",
    "    z = Xtr @ theta\n",
    "    yhat = sigmoid(z)\n",
    "    # gradient: (1/m) X^T (yhat - y)\n",
    "    grad = (Xtr.T @ (yhat - y_train)) / Xtr.shape[0]\n",
    "    theta -= alpha * grad\n",
    "\n",
    "    if t % 50 == 0 or t == epochs-1:\n",
    "        loss = log_loss(y_train, yhat)\n",
    "        loss_history.append((t, loss))\n",
    "\n",
    "loss_history[-5:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e3d8f-e4a5-4cbd-a2c6-f648872d80f9",
   "metadata": {},
   "source": [
    "# Logistic Regression: Math to Code\n",
    "\n",
    "- The linear combination \\( z \\) can be implemented as a matrix multiplication of input features \\( X \\) and parameters \\( \\theta \\):\n",
    "\n",
    "  $$\n",
    "  z = X \\theta \\quad \\text{implements} \\quad z = w_0 + \\sum_j w_j x_j\n",
    "  $$\n",
    "\n",
    "- The predicted probability \\( \\hat{y} \\) (or hypothesis \\( h_\\theta(x) \\)) is the sigmoid of \\( z \\):\n",
    "\n",
    "  $$\n",
    "  \\hat{y} = \\sigma(z) \\quad \\text{implements} \\quad h_\\theta(x) = \\sigma(z)\n",
    "  $$\n",
    "\n",
    "- The gradient of the loss function with respect to parameters \\( \\theta \\) is computed as:\n",
    "\n",
    "  $$\n",
    "  \\frac{X^\\top (\\hat{y} - y)}{m} \\quad \\text{which is} \\quad \\nabla_\\theta J\n",
    "  $$\n",
    "\n",
    "- The parameters are updated by stepping down the gradient with a learning rate \\( \\alpha \\):\n",
    "\n",
    "  $$\n",
    "  \\theta := \\theta - \\alpha \\cdot \\text{gradient}\n",
    "  $$\n",
    "\n",
    "This directly corresponds to the gradient descent update step in logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2980215-1aa3-4c21-8c3e-5a00e1ad2315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "its, losses = zip(*loss_history)\n",
    "plt.figure()\n",
    "plt.plot(its, losses, marker='o')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Train Log Loss\")\n",
    "plt.title(\"From-scratch logistic regression: training loss\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19060bb4-412e-408c-9b19-b9784f1f1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9736842105263158\n",
      "Precision: 0.975609756097561\n",
      "Recall   : 0.9523809523809523\n",
      "F1       : 0.963855421686747\n",
      "ROC AUC  : 0.996362433862434\n",
      "\n",
      "Confusion matrix:\n",
      " [[71  1]\n",
      " [ 2 40]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        72\n",
      "           1       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predictions and metrics (default threshold 0.5)\n",
    "proba_te = sigmoid(Xte @ theta)\n",
    "pred_te = (proba_te >= 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_test, pred_te))\n",
    "print(\"Precision:\", precision_score(y_test, pred_te))\n",
    "print(\"Recall   :\", recall_score(y_test, pred_te))\n",
    "print(\"F1       :\", f1_score(y_test, pred_te))\n",
    "print(\"ROC AUC  :\", roc_auc_score(y_test, proba_te))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, pred_te))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, pred_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eb0a301-9ecc-483d-adcb-8221d9b3f7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.942529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.963855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision    recall        f1\n",
       "0        0.1   0.911111  0.976190  0.942529\n",
       "1        0.2   0.931818  0.976190  0.953488\n",
       "2        0.3   0.953488  0.976190  0.964706\n",
       "3        0.4   0.976190  0.976190  0.976190\n",
       "4        0.5   0.975610  0.952381  0.963855\n",
       "5        0.6   1.000000  0.928571  0.962963\n",
       "6        0.7   1.000000  0.904762  0.950000\n",
       "7        0.8   1.000000  0.904762  0.950000\n",
       "8        0.9   1.000000  0.809524  0.894737"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "rows = []\n",
    "for thr in thresholds:\n",
    "    pred = (proba_te >= thr).astype(int)\n",
    "    rows.append({\n",
    "        \"threshold\": thr,\n",
    "        \"precision\": precision_score(y_test, pred),\n",
    "        \"recall\":    recall_score(y_test, pred),\n",
    "        \"f1\":        f1_score(y_test, pred)\n",
    "    })\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c943cb-7a2d-4fda-863f-16e599cd2ba5",
   "metadata": {},
   "source": [
    "- Compare with scikit-learn’s LogisticRegression (strong baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b95ffda3-ea87-4a46-973c-d7e5a531fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Accuracy : 0.9649122807017544\n",
      "sklearn Precision: 0.975\n",
      "sklearn Recall   : 0.9285714285714286\n",
      "sklearn F1       : 0.9512195121951219\n",
      "sklearn ROC AUC  : 0.996031746031746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=500, solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "sk_proba = pipe.predict_proba(X_test)[:,1]\n",
    "sk_pred  = (sk_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"sklearn Accuracy :\", accuracy_score(y_test, sk_pred))\n",
    "print(\"sklearn Precision:\", precision_score(y_test, sk_pred))\n",
    "print(\"sklearn Recall   :\", recall_score(y_test, sk_pred))\n",
    "print(\"sklearn F1       :\", f1_score(y_test, sk_pred))\n",
    "print(\"sklearn ROC AUC  :\", roc_auc_score(y_test, sk_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26639d-1566-4c16-8580-0bee74ab70db",
   "metadata": {},
   "source": [
    "- Peek at the learned coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aceec6a-b967-4e61-8213-5553166baf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "texture_worst          1.329193\n",
       "radius_se              1.179337\n",
       "symmetry_worst         1.041875\n",
       "radius_worst           0.968606\n",
       "area_worst             0.942049\n",
       "compactness_se        -0.903612\n",
       "concave_points_mean    0.869986\n",
       "area_se                0.867428\n",
       "concavity_worst        0.843627\n",
       "perimeter_worst        0.815593\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From-scratch coefficients (theta[0] is intercept)\n",
    "from_scratch = pd.Series(theta[1:], index=feature_names).sort_values(key=np.abs, ascending=False)\n",
    "from_scratch.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5d889-c20e-4c35-9d63-41de8ba89a1a",
   "metadata": {},
   "source": [
    "Interpretation: positive coefficients push the log-odds toward malignant (1) as the feature increases (after standardization); negative coefficients push toward benign (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f11e16-37f8-409b-86f6-75a6e000d731",
   "metadata": {},
   "source": [
    "# Why Each Step Matters (Quick Recap)\n",
    "\n",
    "- Sigmoid & linear score turn a linear combination of features into a probability.\n",
    "\n",
    "- Log loss matches maximum likelihood for Bernoulli outcomes; minimizing it gives the best-fitting parameters under that assumption.\n",
    "\n",
    "- Gradient \n",
    "\n",
    "  $$\n",
    "  \\nabla J = \\frac{1}{m} X^\\top (\\hat{y} - y)\n",
    "  $$\n",
    "\n",
    "  leads to a clean, vectorized descent update.\n",
    "\n",
    "- Standardization keeps features on similar scales so gradient descent behaves well.\n",
    "\n",
    "- Threshold tuning reflects the clinical trade-off between catching malignancies (recall) and avoiding false alarms (precision).\n",
    "\n",
    "# Extras You Can Add\n",
    "\n",
    "- K-fold cross-validation for more robust estimates.\n",
    "\n",
    "- Regularization (L2) in your scratch code by adding \n",
    "\n",
    "  $$\n",
    "  \\lambda \\|\\mathbf{w}\\|_2^2\n",
    "  $$\n",
    "\n",
    "  to the cost function \\(J(\\theta)\\) and \n",
    "\n",
    "  $$\n",
    "  \\lambda \\mathbf{w}\n",
    "  $$\n",
    "\n",
    "  to the gradient (skip the intercept).\n",
    "\n",
    "- Calibration plots (e.g., using `sklearn.calibration`) if you care about well-calibrated probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08e820-b4b2-40a3-bd73-dab05f9cd4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
