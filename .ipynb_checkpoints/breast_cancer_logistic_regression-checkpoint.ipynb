{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Breast Cancer Detection with Logistic Regression (Step by Step)\n", "\n", "We model the probability that a tumor is malignant (label 1) given features $x \\in \\mathbb{R}^n$.\n", "\n", "**Sigmoid (logistic) function**\n", "\\[\n", "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n", "\\]\n", "\n", "**Linear score**\n", "\\[\n", "z = w_0 + w_1 x_1 + \\cdots + w_n x_n = \\mathbf{w}^\\top \\tilde{\\mathbf{x}}\n", "\\]\n", "where $\\tilde{\\mathbf{x}}$ is $x$ with a leading 1 for the intercept.\n", "\n", "**Hypothesis**\n", "\\[\n", "h_\\theta(x) = \\sigma(z)\n", "\\]\n", "\n", "**Binary cross-entropy (log loss) over $m$ samples**\n", "\\[\n", "J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m \\left[ y^{(i)} \\log h_\\theta(x^{(i)}) + (1 - y^{(i)}) \\log \\big(1 - h_\\theta(x^{(i)})\\big) \\right]\n", "\\]\n", "\n", "**Gradient (vectorized)**\n", "\\[\n", "\\nabla_{\\theta} J = \\frac{1}{m}\\, X^\\top \\big( \\hat{\\mathbf{y}} - \\mathbf{y} \\big),\n", "\\quad \\text{where } \\hat{\\mathbf{y}}=\\sigma(X\\theta)\n", "\\]\n", "\n", "**Gradient descent update**\n", "\\[\n", "\\theta \\leftarrow \\theta - \\alpha \\, \\nabla_{\\theta} J\n", "\\]"]}, {"cell_type": "code", "metadata": {}, "source": ["import io, zipfile, requests\n", "import pandas as pd\n", "import numpy as np\n", "\n", "# Direct ZIP from UCI (contains wdbc.data and wdbc.names)\n", "UCI_ZIP_URL = \"https://archive.ics.uci.edu/static/public/17/breast%2Bcancer%2Bwisconsin%2Bdiagnostic.zip\"\n", "\n", "resp = requests.get(UCI_ZIP_URL)\n", "resp.raise_for_status()\n", "\n", "with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:\n", "    with zf.open('wdbc.data') as f:\n", "        base = ['radius','texture','perimeter','area','smoothness',\n", "                'compactness','concavity','concave_points','symmetry','fractal_dimension']\n", "        feature_names = [f\"{b}_{stat}\" for stat in ['mean','se','worst'] for b in base]\n", "        cols = ['ID','Diagnosis'] + feature_names\n", "        df = pd.read_csv(f, header=None, names=cols)\n", "\n", "df['target'] = (df['Diagnosis'] == 'M').astype(int)\n", "df.head()"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "X = df[feature_names].values\n", "y = df['target'].values\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.2, stratify=y, random_state=42\n", ")\n", "\n", "scaler = StandardScaler().fit(X_train)\n", "X_train_std = scaler.transform(X_train)\n", "X_test_std  = scaler.transform(X_test)\n", "X_train_std.shape, X_test_std.shape, y_train.shape"]}, {"cell_type": "code", "metadata": {}, "source": ["def sigmoid(z):\n", "    z = np.clip(z, -500, 500)\n", "    return 1.0 / (1.0 + np.exp(-z))\n", "\n", "def log_loss(y_true, y_hat, eps=1e-12):\n", "    y_hat = np.clip(y_hat, eps, 1-eps)\n", "    return -np.mean(y_true*np.log(y_hat) + (1-y_true)*np.log(1-y_hat))\n", "\n", "def add_intercept(X):\n", "    return np.c_[np.ones((X.shape[0], 1)), X]\n", "\n", "Xtr = add_intercept(X_train_std)\n", "Xte = add_intercept(X_test_std)\n", "\n", "rng = np.random.default_rng(0)\n", "theta = rng.normal(scale=0.01, size=Xtr.shape[1])\n", "\n", "alpha = 0.1\n", "epochs = 2000\n", "\n", "loss_history = []\n", "for t in range(epochs):\n", "    z = Xtr @ theta\n", "    yhat = sigmoid(z)\n", "    grad = (Xtr.T @ (yhat - y_train)) / Xtr.shape[0]\n", "    theta -= alpha * grad\n", "    if t % 50 == 0 or t == epochs-1:\n", "        loss = log_loss(y_train, yhat)\n", "        loss_history.append((t, loss))\n", "\n", "loss_history[-5:]"]}, {"cell_type": "code", "metadata": {}, "source": ["import matplotlib.pyplot as plt\n", "\n", "its, losses = zip(*loss_history)\n", "plt.figure()\n", "plt.plot(its, losses, marker='o')\n", "plt.xlabel(\"Iteration\")\n", "plt.ylabel(\"Train Log Loss\")\n", "plt.title(\"From-scratch logistic regression: training loss\");"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n", "\n", "proba_te = sigmoid(Xte @ theta)\n", "pred_te = (proba_te >= 0.5).astype(int)\n", "\n", "print(\"Accuracy :\", accuracy_score(y_test, pred_te))\n", "print(\"Precision:\", precision_score(y_test, pred_te))\n", "print(\"Recall   :\", recall_score(y_test, pred_te))\n", "print(\"F1       :\", f1_score(y_test, pred_te))\n", "print(\"ROC AUC  :\", roc_auc_score(y_test, proba_te))\n", "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, pred_te))\n", "print(\"\\nClassification report:\\n\", classification_report(y_test, pred_te))"]}, {"cell_type": "code", "metadata": {}, "source": ["thresholds = np.linspace(0.1, 0.9, 9)\n", "rows = []\n", "for thr in thresholds:\n", "    pred = (proba_te >= thr).astype(int)\n", "    rows.append({\n", "        \"threshold\": thr,\n", "        \"precision\": precision_score(y_test, pred),\n", "        \"recall\":    recall_score(y_test, pred),\n", "        \"f1\":        f1_score(y_test, pred)\n", "    })\n", "pd.DataFrame(rows)"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.pipeline import Pipeline\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "pipe = Pipeline([\n", "    (\"scaler\", StandardScaler()),\n", "    (\"lr\", LogisticRegression(max_iter=500, solver=\"lbfgs\"))\n", "])\n", "\n", "pipe.fit(X_train, y_train)\n", "sk_proba = pipe.predict_proba(X_test)[:,1]\n", "sk_pred  = (sk_proba >= 0.5).astype(int)\n", "\n", "print(\"sklearn Accuracy :\", accuracy_score(y_test, sk_pred))\n", "print(\"sklearn Precision:\", precision_score(y_test, sk_pred))\n", "print(\"sklearn Recall   :\", recall_score(y_test, sk_pred))\n", "print(\"sklearn F1       :\", f1_score(y_test, sk_pred))\n", "print(\"sklearn ROC AUC  :\", roc_auc_score(y_test, sk_proba))"]}, {"cell_type": "code", "metadata": {}, "source": ["from_scratch = pd.Series(theta[1:], index=feature_names).sort_values(key=np.abs, ascending=False)\n", "from_scratch.head(10)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}